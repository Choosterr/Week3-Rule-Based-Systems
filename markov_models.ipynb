{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gMFcaF8EITS"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAT-ComputationalCreativity-Spring2025/Week3-Rule-Based-Systems/blob/main/markov_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ-Pe73yEITU"
      },
      "source": [
        "# Markov Models Text Generation\n",
        "\n",
        "This notebook introduces Markov chains for text generation. We'll build a simple\n",
        "text generator that learns patterns from input text and generates new text with\n",
        "similar statistical properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UJNYqHrsEITW"
      },
      "outputs": [],
      "source": [
        "# First, let's import our required libraries\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_QEtNflEITX"
      },
      "source": [
        "## Building the Markov Chain\n",
        "\n",
        "A Markov chain represents sequences of states where the probability of each state\n",
        "depends only on the previous state(s). In our case, each state will be a sequence\n",
        "of words, and we'll predict the next word based on this sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FNg5Czk0EITX"
      },
      "outputs": [],
      "source": [
        "def build_markov_chain(text, order=2):\n",
        "    \"\"\"\n",
        "    Build a Markov chain from input text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to learn from\n",
        "        order (int): Number of words to use as state (context)\n",
        "\n",
        "    Returns:\n",
        "        dict: Mapping from state tuples to lists of possible next words\n",
        "    \"\"\"\n",
        "    chain = defaultdict(list)\n",
        "    words = text.split()\n",
        "\n",
        "    for i in range(len(words) - order):\n",
        "        # Create state tuple from current words\n",
        "        state = tuple(words[i:i+order])\n",
        "        # Get the next word\n",
        "        next_word = words[i+order]\n",
        "        # Add to chain\n",
        "        chain[state].append(next_word)\n",
        "\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn6xr7bbEITY"
      },
      "source": [
        "## Generating Text\n",
        "\n",
        "Now we'll use our Markov chain to generate new text. We'll randomly select from\n",
        "the possible next words at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MAIK7JDzEITZ"
      },
      "outputs": [],
      "source": [
        "def generate_text(chain, num_words=30):\n",
        "    \"\"\"\n",
        "    Generate new text using the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain mapping states to possible next words\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    # Start with a random state from the chain\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            next_word = random.choice(chain[state])\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebTVTth-EITZ"
      },
      "source": [
        "## Part 3: Basic Example\n",
        "\n",
        "Let's try our text generator with a simple example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0keL0YKDEITa",
        "outputId": "6508422b-583f-4201-b31b-f92dad677273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick -> ['brown']\n",
            "quick brown -> ['fox', 'dog', 'dog']\n",
            "brown fox -> ['jumps']\n",
            "fox jumps -> ['over']\n",
            "jumps over -> ['the', 'the']\n",
            "over the -> ['lazy', 'lazy']\n",
            "the lazy -> ['dog.', 'fox.']\n",
            "lazy dog. -> ['A']\n",
            "dog. A -> ['quick']\n",
            "A quick -> ['brown']\n",
            "brown dog -> ['jumps', 'watches.']\n",
            "dog jumps -> ['over']\n",
            "lazy fox. -> ['The']\n",
            "fox. The -> ['lazy']\n",
            "The lazy -> ['fox']\n",
            "lazy fox -> ['sleeps']\n",
            "fox sleeps -> ['while']\n",
            "sleeps while -> ['the']\n",
            "while the -> ['quick']\n",
            "the quick -> ['brown']\n"
          ]
        }
      ],
      "source": [
        "# Sample text\n",
        "sample_text = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "A quick brown dog jumps over the lazy fox.\n",
        "The lazy fox sleeps while the quick brown dog watches.\n",
        "\"\"\"\n",
        "\n",
        "# Build the chain\n",
        "chain = build_markov_chain(sample_text)\n",
        "\n",
        "# Examine the chain\n",
        "for state, words in chain.items():\n",
        "    print(f\"{' '.join(state)} -> {words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZhalW1ZzEITa",
        "outputId": "717ecede-c68f-48e3-9e29-48c9c0c221ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "while the quick brown dog jumps over the lazy dog. A quick brown dog watches.\n"
          ]
        }
      ],
      "source": [
        "# Generate some text\n",
        "print(\"Generated text:\")\n",
        "print(generate_text(chain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFemVYuqEITa"
      },
      "source": [
        "## Student Tasks\n",
        "\n",
        "1. Basic Implementation:\n",
        "   - Try changing the order parameter in build_markov_chain\n",
        "   - What happens with order=1 vs order=3?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mhWtEgAsEITb",
        "outputId": "41f16ba6-6b94-49b6-deda-5eb3eb204c68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Order 1:\n",
            "The lazy fox sleeps while the quick brown dog jumps over the quick brown fox sleeps while the lazy fox. The lazy fox sleeps while the quick brown fox sleeps\n",
            "\n",
            "Order 3:\n",
            "brown fox jumps over the lazy fox. The lazy fox sleeps while the quick brown dog jumps over the lazy fox. The lazy fox sleeps while the quick brown dog\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Experiment with different orders\n",
        "print(\"\\nOrder 1:\")\n",
        "chain1 = build_markov_chain(sample_text, order=1)\n",
        "print(generate_text(chain1))\n",
        "\n",
        "print(\"\\nOrder 3:\")\n",
        "chain3 = build_markov_chain(sample_text, order=3)\n",
        "print(generate_text(chain3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab8iJAmvEITb"
      },
      "source": [
        "2. Use Your Own Text:\n",
        "   Below, try using a different text source. You could use:\n",
        "   - Song lyrics\n",
        "   - Book excerpts\n",
        "   - Movie quotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HXSebKSiEITb"
      },
      "outputs": [],
      "source": [
        "# Task 2: Add your own text here\n",
        "myText = \"\"\"\n",
        "Look, if you had one shot or one opportunity\n",
        "To seize everything you ever wanted in one moment\n",
        "Would you capture it or just let it slip?\n",
        "Yo\n",
        "\n",
        "His palms are sweaty, knees weak, arms are heavy\n",
        "There's vomit on his sweater already, mom's spaghetti\n",
        "He's nervous, but on the surface, he looks calm and ready\n",
        "To drop bombs, but he keeps on forgetting\n",
        "What he wrote down, the whole crowd goes so loud\n",
        "He opens his mouth, but the words won't come out\n",
        "He's chokin', how? Everybody's jokin' now\n",
        "The clock's run out, time's up, over, blaow\n",
        "Snap back to reality, ope, there goes gravity\n",
        "Ope, there goes Rabbit, he choked, he's so mad\n",
        "But he won't give up that easy, no, he won't have it\n",
        "He knows his whole back's to these ropes, it don't matter\n",
        "He's dope, he knows that, but he's broke, he's so stagnant\n",
        "He knows when he goes back to this mobile home, that's when it's\n",
        "Back to the lab again, yo, this old rhapsody\n",
        "Better go capture this moment and hope it don't pass him\n",
        "\n",
        "\n",
        "You better lose yourself in the music\n",
        "The moment, you own it, you better never let it go (Go)\n",
        "You only get one shot, do not miss your chance to blow\n",
        "This opportunity comes once in a lifetime, yo\n",
        "You better lose yourself in the music\n",
        "The moment, you own it, you better never let it go (Go)\n",
        "You only get one shot, do not miss your chance to blow\n",
        "This opportunity comes once in a lifetime, yo\n",
        "You better\n",
        "\n",
        "His soul's escaping through this hole that is gaping\n",
        "This world is mine for the taking, make me king\n",
        "As we move toward a new world order\n",
        "A normal life is boring, but superstardom's\n",
        "Close to post-mortem, it only grows harder\n",
        "Homie grows hotter, he blows, it's all over\n",
        "These hoes is all on him, coast-to-coast shows\n",
        "He's known as the Globetrotter, lonely roads\n",
        "God only knows he's grown farther from home, he's no father\n",
        "He goes home and barely knows his own daughter\n",
        "But hold your nose 'cause here goes the cold water\n",
        "These hoes don't want him no mo', he's cold product\n",
        "They moved on to the next schmoe who flows\n",
        "He nose-dove and sold nada, and so the soap opera\n",
        "Is told, it unfolds, I suppose it's old, partner\n",
        "But the beat goes on, da-da-dom, da-dom, dah-dah-dah-dah\n",
        "\n",
        "You better lose yourself in the music\n",
        "The moment, you own it, you better never let it go (Go)\n",
        "You only get one shot, do not miss your chance to blow\n",
        "This opportunity comes once in a lifetime, yo\n",
        "You better lose yourself in the music\n",
        "The moment, you own it, you better never let it go (Go)\n",
        "You only get one shot, do not miss your chance to blow\n",
        "This opportunity comes once in a lifetime, yo\n",
        "You better\n",
        "\n",
        "No more games, I'ma change what you call rage\n",
        "Tear this motherfuckin' roof off like two dogs caged\n",
        "I was playin' in the beginning, the mood all changed\n",
        "I've been chewed up and spit out and booed off stage\n",
        "But I kept rhymin' and stepped right in the next cypher\n",
        "Best believe somebody's payin' the Pied Piper\n",
        "All the pain inside amplified by the\n",
        "Fact that I can't get by with my nine-to-\n",
        "Five and I can't provide the right type of life for my family\n",
        "'Cause, man, these goddamn food stamps don't buy diapers\n",
        "And there's no movie, there's no Mekhi Phifer, this is my life\n",
        "And these times are so hard, and it's gettin' even harder\n",
        "Tryna feed and water my seed, plus teeter-totter\n",
        "Caught up between bein' a father and a prima donna\n",
        "Baby-mama drama, screamin' on her, too much for me to wanna\n",
        "Stay in one spot, another day of monotony's gotten me\n",
        "To the point I'm like a snail, I've got\n",
        "To formulate a plot or end up in jail or shot\n",
        "Success is my only motherfuckin' option, failure's not\n",
        "Mom, I love you, but this trailer's got\n",
        "To go, I cannot grow old in Salem's Lot\n",
        "So here I go, it's my shot; feet, fail me not\n",
        "This may be the only opportunity that I got\n",
        "\n",
        "You better lose yourself in the music\n",
        "The moment, you own it, you better never let it go (Go)\n",
        "You only get one shot, do not miss your chance to blow\n",
        "This opportunity comes once in a lifetime, yo\n",
        "You better lose yourself in the music\n",
        "The moment, you own it, you better never let it go (Go)\n",
        "You only get one shot, do not miss your chance to blow\n",
        "This opportunity comes once in a lifetime, yo\n",
        "You better\n",
        "\"\"\"\n",
        "\n",
        "# Build the chain\n",
        "myChain = build_markov_chain(myText)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dODxS5TqEITb"
      },
      "source": [
        "3. Advanced Implementation:\n",
        "   Add temperature-based sampling to control randomness"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment with different orders\n",
        "print(\"\\nOrder 1:\")\n",
        "myChain1 = build_markov_chain(myText, order=1)\n",
        "print(generate_text(myChain1))\n",
        "\n",
        "print(\"\\nOrder 2:\")\n",
        "myChain2 = build_markov_chain(myText, order=2)\n",
        "print(generate_text(myChain2))\n",
        "\n",
        "print(\"\\nOrder 3:\")\n",
        "myChain3 = build_markov_chain(myText, order=3)\n",
        "print(generate_text(myChain3))"
      ],
      "metadata": {
        "id": "jdCIoMrvF_sT",
        "outputId": "e6639950-ae22-4139-810e-c14419a4052c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Order 1:\n",
            "He goes back to these ropes, it go capture this motherfuckin' roof off stage But hold your chance to blow This opportunity To seize everything you own it, you own\n",
            "\n",
            "Order 2:\n",
            "the pain inside amplified by the Fact that I got You better lose yourself in the music The moment, you own it, you better never let it go (Go) You\n",
            "\n",
            "Order 3:\n",
            "in Salem's Lot So here I go, it's my shot; feet, fail me not This may be the only opportunity that I got You better lose yourself in the music\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tM-zItOUEITb",
        "outputId": "297c2e4c-90ae-4625-d75c-7a079d0470d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Low temperature (more predictable):\n",
            "that's when it's Back to the next schmoe who flows He nose-dove and sold nada, and so the soap opera Is told, it unfolds, I suppose it's old, partner But\n",
            "\n",
            "High temperature (more random):\n",
            "told, it only get one shot Success is all changed I've got You better lose yourself in the next cypher Best believe somebody's payin' the beat goes home and it's\n"
          ]
        }
      ],
      "source": [
        "def generate_text_with_temperature(chain, temperature=1.0, num_words=30):\n",
        "    \"\"\"\n",
        "    Generate text with temperature-based sampling.\n",
        "    Lower temperature = more conservative/predictable\n",
        "    Higher temperature = more random/creative\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain\n",
        "        temperature (float): Controls randomness (0.1 to 2.0 recommended)\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "    \"\"\"\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            # Count frequencies of next words\n",
        "            next_words = chain[state]\n",
        "            word_counts = defaultdict(int)\n",
        "            for word in next_words:\n",
        "                word_counts[word] += 1\n",
        "\n",
        "            # Apply temperature\n",
        "            weights = [count ** (1.0 / temperature) for count in word_counts.values()]\n",
        "            total = sum(weights)\n",
        "            weights = [w/total for w in weights]\n",
        "\n",
        "            # Choose next word based on weighted probabilities\n",
        "            next_word = random.choices(list(word_counts.keys()), weights=weights)[0]\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Try different temperatures\n",
        "print(\"\\nLow temperature (more predictable):\")\n",
        "print(generate_text_with_temperature(myChain2, temperature=0.3))\n",
        "\n",
        "print(\"\\nHigh temperature (more random):\")\n",
        "print(generate_text_with_temperature(myChain1, temperature=2.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv0kRPTHEITc"
      },
      "source": [
        "## Challenge Tasks:\n",
        "\n",
        "1. Implement a function to analyze the Markov chain:\n",
        "   - Count the number of unique states\n",
        "   - Find the most common transitions\n",
        "   - Calculate the average number of possible next words for each state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i2ti_bphEITc",
        "outputId": "6ccd88d2-4305-4504-ef5d-2f77527bfedc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chain Analysis:\n",
            "Number of unique states: 20\n",
            "Average transitions per state: 1.30\n",
            "\n",
            "Most common transitions:\n",
            "The quick -> brown (count: 1)\n",
            "quick brown -> dog (count: 2)\n",
            "brown fox -> jumps (count: 1)\n",
            "fox jumps -> over (count: 1)\n",
            "jumps over -> the (count: 2)\n"
          ]
        }
      ],
      "source": [
        "def analyze_chain(chain):\n",
        "    \"\"\"\n",
        "    Analyze properties of the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain to analyze\n",
        "    \"\"\"\n",
        "    num_states = len(chain)\n",
        "    total_transitions = sum(len(next_words) for next_words in chain.values())\n",
        "    avg_transitions = total_transitions / num_states if num_states > 0 else 0\n",
        "\n",
        "    # Find most common next word for each state\n",
        "    most_common = {}\n",
        "    for state, next_words in chain.items():\n",
        "        word_counts = defaultdict(int)\n",
        "        for word in next_words:\n",
        "            word_counts[word] += 1\n",
        "        most_common[state] = max(word_counts.items(), key=lambda x: x[1])\n",
        "\n",
        "    print(f\"Number of unique states: {num_states}\")\n",
        "    print(f\"Average transitions per state: {avg_transitions:.2f}\")\n",
        "    print(\"\\nMost common transitions:\")\n",
        "    for state, (word, count) in list(most_common.items())[:5]:  # Show top 5\n",
        "        print(f\"{' '.join(state)} -> {word} (count: {count})\")\n",
        "\n",
        "# Analyze our chain\n",
        "print(\"\\nChain Analysis:\")\n",
        "analyze_chain(chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg02CboYEITc"
      },
      "source": [
        "## Further Exploration:\n",
        "\n",
        "Other ideas to try:\n",
        "1. Modify the code to preserve punctuation\n",
        "2. Add start-of-sentence and end-of-sentence tokens\n",
        "3. Implement bi-directional generation\n",
        "4. Create a chain that works with characters instead of words\n",
        "5. Add input validation and error handling"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "iat460",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}